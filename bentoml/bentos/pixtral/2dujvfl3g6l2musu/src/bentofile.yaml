service: "service:VLLM"
labels:
  source: https://github.com/bentoml/openllm-models/tree/main/src/vllm-chat
  platforms: linux
include:
- "*.py"
- "*.yaml"
- "ui/*"
- "ui/chunks/*"
- "ui/css/*"
- "ui/media/*"
- "ui/chunks/pages/*"
python:
  requirements_txt: "./requirements.txt"
