service: "service:VLLM"
labels:
  owner: bentoml-team
  platforms: linux
  source_repo: https://github.com/bentoml/openllm-repo-recipe.git
  source_directory: vllm-chat
  service_home: /chat
include:
- "*.py"
- "ui/*"
- "ui/chunks/*"
- "ui/css/*"
- "ui/media/*"
- "ui/chunks/pages/*"
- "bentovllm_openai/*.py"
- "chat_templates/chat_templates/*.jinja"
- "chat_templates/generation_configs/*.json"
python:
  requirements_txt: "./requirements.txt"
  lock_packages: false
envs:
  - name: HF_TOKEN
