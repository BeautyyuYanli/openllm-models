"phi3:3.8b-mini-instruct-4k-fp16":
  alias:
    - latest
    - 3.8b
    - instruct
    - mini
  project: vllm-chat
  service_config:
    name: phi3
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-t4
  engine_config:
    model: microsoft/Phi-3-mini-4k-instruct
    max_model_len: 4096
    dtype: half
  chat_template: phi-3
"llama2:7b-chat-fp16":
  alias:
    - latest
    - 7b
    - 7b-chat
  project: vllm-chat
  service_config:
    name: llama2
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-t4
  engine_config:
    model: meta-llama/Llama-2-7b-chat-hf
    max_model_len: 1024
  chat_template: llama-2-chat
"llama2:7b-chat-awq-4bit":
  alias:
    - 7b-4bit
    - 7b-chat-4bit
  project: vllm-chat
  service_config:
    name: llama2
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: TheBloke/Llama-2-7B-Chat-AWQ
    max_model_len: 1024
    quantization: awq
    enforce_eager: true
  chat_template: llama-2-chat
"mistral:7b-instruct-awq-4bit":
  alias:
    - 7b-4bit
    - 7b-instruct-4bit
  project: vllm-chat
  service_config:
    name: mistral
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: TheBloke/Mistral-7B-Instruct-v0.1-AWQ
    max_model_len: 1024
    quantization: awq
    enforce_eager: true
    dtype: half
  chat_template: mistral-instruct
"mistral:7b-instruct-fp16":
  alias:
    - 7b
    - 7b-instruct
    - 7b-instruct-v0.1
  project: vllm-chat
  service_config:
    name: mistral
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-l4
  engine_config:
    model: mistralai/Mistral-7B-Instruct-v0.1
    max_model_len: 1024
    enforce_eager: true
    dtype: half
  chat_template: mistral-instruct
"llama3:8b-instruct-awq-4bit":
  alias:
    - 8b-4bit
    - 8b-instruct-4bit
  project: vllm-chat
  service_config:
    name: llama3
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: casperhansen/llama-3-8b-instruct-awq
    max_model_len: 2048
    quantization: awq
"llama3:70b-instruct-awq-4bit":
  alias:
    - 70b-4bit
    - 70b-instruct-4bit
  project: vllm-chat
  service_config:
    name: llama3
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-a100-80g
  engine_config:
    model: meta-llama/Meta-Llama-3-8B
    max_model_len: 2048
    quantization: awq
"llama3:8b-instruct-fp16":
  alias:
    - latest
    - 8b
    - 8b-instruct
  project: vllm-chat
  service_config:
    name: llama3
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-l4
  engine_config:
    model: meta-llama/Meta-Llama-3-8B-Instruct
    max_model_len: 2048
"llama3:70b-instruct-fp16":
  alias:
    - latest
    - 70b
    - 70b-instruct
  project: vllm-chat
  service_config:
    name: llama3
    traffic:
      timeout: 300
    resources:
      gpu: 2
      gpu_type: nvidia-a100-80g
  engine_config:
    model: meta-llama/Meta-Llama-3-70B-Instruct
    max_model_len: 2048
"gemma:2b-instruct-fp16":
  alias:
    - latest
    - 2b
    - 2b-instruct
  project: vllm-chat
  service_config:
    name: gemma
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: google/gemma-2b-it
    max_model_len: 2048
"gemma:7b-instruct-fp16":
  alias:
    - latest
    - 7b
    - 7b-instruct
  project: vllm-chat
  service_config:
    name: gemma
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-tesla-l4
  engine_config:
    model: google/gemma-7b-it
    max_model_len: 2048
"gemma:7b-instruct-awq-4bit":
  alias:
    - 7b-4bit
    - 7b-instruct-4bit
  project: vllm-chat
  service_config:
    name: gemma
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-rtx-3060
  engine_config:
    model: casperhansen/gemma-7b-it-awq
    max_model_len: 2048
    quantization: awq
  chat_template: gemma-it
