'qwen2.5:72b-q8-3090-4':
  project: vllm-chat
  service_config:
    name: qwen2.5
    traffic:
      timeout: 300
    resources:
      gpu: 1
      gpu_type: nvidia-a100-80g
  engine_config:
    model: Qwen/Qwen2.5-72B-Instruct-GPTQ-Int8
    dtype: auto
    tensor-parallel-size: 4
  extra_labels:
    openllm_alias: 72b,72b-instruct
    model_name: Qwen/Qwen2.5-72B-Instruct
